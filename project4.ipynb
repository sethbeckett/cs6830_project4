{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34d91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import sklearn.preprocessing as pre # need OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA # Use to check feature importance?\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sktime.datasets import load_osuleaf\n",
    "from tslearn.metrics import dtw\n",
    "from sklearn.neighbors import KNeighborsClassifier # This is only used in part 2, since it's not allowed in part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a5d2a",
   "metadata": {},
   "source": [
    "## First let's Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a12a808c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca  thal  num  \n",
       "0      3.0  0.0   6.0  0.0  \n",
       "1      2.0  3.0   3.0  2.0  \n",
       "2      2.0  2.0   7.0  1.0  \n",
       "3      3.0  0.0   3.0  0.0  \n",
       "4      1.0  0.0   3.0  0.0  \n",
       "..     ...  ...   ...  ...  \n",
       "298    2.0  0.0   7.0  1.0  \n",
       "299    2.0  2.0   7.0  2.0  \n",
       "300    2.0  1.0   7.0  3.0  \n",
       "301    2.0  1.0   3.0  1.0  \n",
       "302    1.0  0.0   3.0  0.0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleveland.csv').replace({'ca': '?', 'thal': '?'},{'ca': '0.0', 'thal': '3.0'}).astype(float, errors='ignore')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88db875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories: sex (1,0), cp (1,2,3,4), fbs (1,0), exang (1,0), thal (3,6,7), num (0,{1,2,3,4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4fdf91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change num to either 0 or 1.\n",
    "\n",
    "df['num'] = [0.0 if df['num'][i] == 0.0 else 1.0 for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae3e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df, columns=['sex','cp','fbs','exang','thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e08bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X and y pairs.\n",
    "Xdf = df2.drop(columns=['num'])\n",
    "Ydf = df['num']\n",
    "X = Xdf.to_numpy()\n",
    "y = Ydf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c6acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to standardize the data.\n",
    "myscaler = pre.StandardScaler(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b0e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "myscaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b1382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the more important features?\n",
    "pca1 = PCA(n_components=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b92b710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9bab916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.20079218e+01, 2.29636027e+01, 2.23143922e+01, 1.88413585e+01,\n",
       "       1.77355047e+01, 1.71818558e+01, 1.62948592e+01, 1.55678708e+01,\n",
       "       1.46068733e+01, 1.42664357e+01, 1.38081854e+01, 1.30447824e+01,\n",
       "       1.24200321e+01, 1.15874077e+01, 9.43488566e+00, 8.88520073e+00,\n",
       "       5.29431176e-15, 4.21042736e-15, 3.44436481e-15, 2.91416101e-15,\n",
       "       2.35420553e-15])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bddab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how we'll predict using NearestNeighbors.\n",
    "def kPredict(indices,y):\n",
    "    ypreds = []\n",
    "    for mylist in indices:\n",
    "        preds = [y[i] for i in mylist]\n",
    "        pred = max(set(preds), key=preds.count)\n",
    "        ypreds += [pred]\n",
    "        \n",
    "    return ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f2e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our monte carlo cross validation.\n",
    "def myCV(Xdf,Ydf,k,p,cv=10):\n",
    "    # already perfomed 1-hot encoding, gotten rid of '?' and converted to float.\n",
    "    X = Xdf.to_numpy()\n",
    "    y = Ydf.to_numpy()\n",
    "    myscaler = pre.StandardScaler(copy=False)\n",
    "    myscaler.fit_transform(X)\n",
    "    scores=[]\n",
    "    for v in range(cv):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/cv)\n",
    "        pca = PCA(n_components=p)\n",
    "        pca.fit(X_train) # fit according to the training data\n",
    "        Xtr = pca.transform(X_train) # transform the training data\n",
    "        Xte = pca.transform(X_test) # transform the test data for later use.\n",
    "        knn = NearestNeighbors(n_neighbors=k)\n",
    "        knn.fit(Xtr, y_train)\n",
    "        dists, neighs = knn.kneighbors(Xte) # find the test sets' nearest neighbors in the training set.\n",
    "        preds = kPredict(neighs,y_train)\n",
    "        #PrecisionScore = precision_score(preds,y_test)\n",
    "        #RecallScore = recall_score(preds,y_test)\n",
    "        F1Score = f1_score(preds,y_test) # compute the f1 score.\n",
    "        #AccuracyScoreScore = accuracy_score(preds,y_test)\n",
    "        scores += [F1Score]\n",
    "        \n",
    "    avg_score = sum(scores)/len(scores)\n",
    "    return [k,p,avg_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ded9005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 0.7417161040610198]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it:\n",
    "myCV(Xdf,Ydf,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6e80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many principal components and number \"k\" is ideal.\n",
    "def myGridSearch(Xdf,Ydf,list1,list2,cv=10):\n",
    "    output = []\n",
    "    for k in list1:\n",
    "        for p in list2:\n",
    "            output += [myCV(Xdf,Ydf,k,p,cv=cv)]\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29778642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll run our grid search three times to see if one comes out on top consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cc3b08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 0.7943788778834417],\n",
       " [3, 5, 0.7338794235002013],\n",
       " [3, 7, 0.7658991157558407],\n",
       " [5, 3, 0.7834670076088841],\n",
       " [5, 5, 0.7633071431605913],\n",
       " [5, 7, 0.8011946694255541],\n",
       " [7, 3, 0.7900075034171143],\n",
       " [7, 5, 0.7868963010424112],\n",
       " [7, 7, 0.7497906403940886]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGridSearch(Xdf,Ydf,[3,5,7],[3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46bb14f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 0.7880995163531315],\n",
       " [3, 5, 0.7097583708262241],\n",
       " [3, 7, 0.7525971400164949],\n",
       " [5, 3, 0.7498981099164309],\n",
       " [5, 5, 0.7658084843561517],\n",
       " [5, 7, 0.8155179228567533],\n",
       " [7, 3, 0.7419556996393577],\n",
       " [7, 5, 0.832059675225693],\n",
       " [7, 7, 0.8127521236400383]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGridSearch(Xdf,Ydf,[3,5,7],[3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d904a6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 0.7409332238642584],\n",
       " [3, 5, 0.8217372346477546],\n",
       " [3, 7, 0.7555031611178538],\n",
       " [5, 3, 0.7925694617971855],\n",
       " [5, 5, 0.7545959008717629],\n",
       " [5, 7, 0.7773345844669374],\n",
       " [7, 3, 0.7727429052429052],\n",
       " [7, 5, 0.7923869855096155],\n",
       " [7, 7, 0.8063446081116858]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGridSearch(Xdf,Ydf,[3,5,7],[3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "631fbaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like we should choose k=7 and p=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b6478",
   "metadata": {},
   "source": [
    "## Now let's do a test run for the in-class competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff3556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myEval(name,Xdf,Ydf,k,p):\n",
    "    dfTest = pd.read_csv(name).replace({'ca': '?', 'thal': '?'},{'ca': '0.0', 'thal': '3.0'}).astype(float, errors='ignore') # read the data\n",
    "    dfTest = dfTest.drop(columns=['Unnamed: 0']) # not even sure what this column is doing here.\n",
    "    dfTest.iloc[-1] = df.iloc[0] # this makes it so the thal value of 6.0 is included.\n",
    "    df2 = pd.get_dummies(dfTest, columns=['sex','cp','fbs','exang','thal']) # one-hot encode.\n",
    "    df2 = df2.drop([df2.shape[0]-1]) # take out what was artificially inserted.\n",
    "    Xdftest = df2.drop(columns=['disease']) # inputs\n",
    "    #return Xdf\n",
    "    #return Xdftest\n",
    "    Ydftest = df2['disease'] # outputs\n",
    "    #Xtestp = Xdftest.to_numpy() # input to numpy\n",
    "    #ytestp = Ydftest.to_numpy() # outputs to numpy\n",
    "    myscaler = pre.StandardScaler(copy=False) # prepare to standardize. We'll need to standardize the train and test\n",
    "    bigXdf = pd.concat([Xdf,Xdftest]) # temporarily merge the two for standardization.\n",
    "    #return bigXdf\n",
    "    bigX = bigXdf.to_numpy()\n",
    "    #return bigX\n",
    "    myscaler.fit_transform(bigX)\n",
    "    #return bigX.shape\n",
    "    Xtrain = bigX[:Xdf.shape[0]]\n",
    "    Xtest = bigX[Xdf.shape[0]:]\n",
    "    Ytrain = Ydf.to_numpy()\n",
    "    Ytest = Ydftest.to_numpy()\n",
    "    \n",
    "    pca = PCA(n_components=p)\n",
    "    pca.fit(Xtrain)\n",
    "    Xtr = pca.transform(Xtrain) # transform the training data\n",
    "    Xte = pca.transform(Xtest) # transform the test data for later use.\n",
    "    \n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(Xtr, Ytrain)\n",
    "    dists, neighs = knn.kneighbors(Xte) # find the test sets' nearest neighbors in the training set.\n",
    "    preds = kPredict(neighs,Ytrain)\n",
    "    F1Score = f1_score(preds,Ytest)\n",
    "    \n",
    "    return F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7144230d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918918918918919"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myscore = myEval(\"cleveland-test-sample.csv\",Xdf,Ydf,7,5)\n",
    "myscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1efd460",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b714386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl, yl = load_osuleaf(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e48fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl2=Xl.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6968af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(Xl2, yl, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4ea3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl_train = np.array([list(Xl_train[i][0]) for i in range(len(Xl_train))])\n",
    "Xl_test = np.array([list(Xl_test[i][0]) for i in range(len(Xl_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a447ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lknn = KNeighborsClassifier(n_neighbors=5, metric=dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46925d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric=<function dtw at 0x7f1b67fe8040>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lknn.fit(Xl_train, yl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82afb7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6486486486486487"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lknn.score(Xl_test, yl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3811dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
